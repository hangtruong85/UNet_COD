ğŸ“¦ UNet++ + EfficientNet-B2 + BEM (DeformConv) for Camouflaged Object Segmentation

Pipeline nÃ y bao gá»“m:

Backbone: EfficientNet-B2

Decoder: UNet++

Boundary branch: BEM (Boundary Extraction Module, DeformConv)

Metrics chuáº©n paper: S-measure, E-measure, Weighted F-measure (F<sub>w</sub>), MAE

Resume training, checkpoint best-S, logging toÃ n bá»™ quÃ¡ trÃ¬nh

Inference áº£nh Ä‘Æ¡n vÃ  inference toÃ n folder

1ï¸âƒ£ REQUIREMENTS
1.1 Conda environment
ğŸ”¥ Option chuáº©n cho RTX 5090 / CUDA 12.8

LÆ¯U Ã: PyTorch build pháº£i khá»›p CUDA trong driver Ä‘ang cÃ i, khÃ´ng cÃ i kiá»ƒu random.

conda create -n unetpp-bem-camo python=3.11 -y
conda activate unetpp-bem-camo

1.2 CÃ i pytorch & CUDA phÃ¹ há»£p

ğŸ‘‰ Xem hÆ°á»›ng dáº«n chÃ­nh thá»©c:
https://pytorch.org/get-started/locally/

VÃ­ dá»¥ (CUDA 12.x):

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

1.3 CÃ i cÃ¡c dependency cÃ²n láº¡i
pip install segmentation-models-pytorch==0.3.0
pip install timm
pip install albumentations==1.4.6
pip install opencv-python
pip install pyyaml idna
pip install tqdm

2ï¸âƒ£ DATASET STRUCTURE
MHCD / COD10K / CAMO Format (1 class: camouflaged object)
MHCD_seg/
   train/
      images/
          xxx1.jpg
          xxx2.jpg
      masks/
          xxx1.png
          xxx2.png

   val/
      images/
      masks/

   test/
      images/
      masks/


ğŸ‘‰ TÃªn file mask pháº£i khá»›p vá»›i tÃªn áº£nh
VÃ­ dá»¥:

images/tank_001.jpg
masks/tank_001.png

Mask format

1 channel grayscale

pixel values {0,255}

foreground = 255 (object), background = 0

Báº¡n cÃ³ thá»ƒ convert:

mask = (mask > 127).astype(np.float32)

3ï¸âƒ£ TRAINING & VALIDATION
3.1 Run cÆ¡ báº£n
python train.py


Há»‡ thá»‘ng log vÃ o:

logs/train.log
logs/train_log.csv      # metrics tá»«ng epoch
logs/loss_curve.png
logs/last.pth           # checkpoint resume
logs/best_S.pth         # checkpoint cÃ³ S-measure tá»‘t nháº¥t

3.2 Resume Training

Tá»± Ä‘á»™ng resume náº¿u logs/last.pth tá»“n táº¡i.

Náº¿u muá»‘n Ã©p resume:

python train.py --resume

4ï¸âƒ£ METRICS DÃ™NG TRONG CAMOUFLAGE SEGMENTATION
Implement paper-level (chuáº©n benchmark)
Metric	Paper	Ã nghÄ©a
S-measure	ICCV 2017	ÄÃ¡nh giÃ¡ cáº¥u trÃºc foreground
Weighted F-measure	CVPR 2014	Precision-Recall cÃ³ trá»ng sá»‘ spatial
E-measure	IJCAI 2018	Enhanced alignment
MAE	-	TÆ°Æ¡ng Ä‘á»“ng pixel map

ÄÃ¢y lÃ  4 metric tiÃªu chuáº©n bÃ¡o cÃ¡o trong SINet / MFFNet / UGTR / DGNet.

5ï¸âƒ£ TRAINING PARAMETERS

Báº¡n chá»‰nh trong train.py:

epochs = 120
img_size = 256
batch_size = 16
lr = 1e-4


RTX 5090 cho phÃ©p batch 24â€“48 tuá»³ RAM.

6ï¸âƒ£ LOGGING

Há»‡ thá»‘ng log:

Ä‘Æ°á»ng dáº«n áº£nh/mask train & val

sá»‘ lÆ°á»£ng áº£nh train/val

batch size, epochs, lr, img_size

loss train

loss val

S-measure

E-measure

Weighted F-measure (F<sub>w</sub>)

MAE

checkpoint

File log:

logs/train.log

7ï¸âƒ£ INFERENCE
7.1 Inference 1 áº£nh
from inference import inference_single, load_model

model = load_model("logs/best_S.pth", device="cuda")
out = inference_single(
    model,
    img_path="demo.jpg",
    save_dir="infer_out",
    img_size=256
)

print(out)


Output:

infer_out/demo_mask.png

7.2 Inference toÃ n folder
python infer_folder.py \
    --weights logs/best_S.pth \
    --input_folder path/to/test/images \
    --out infer_masks \
    --img_size 256


Káº¿t quáº£:

infer_masks/
   img1_mask.png
   img2_mask.png
   ...

8ï¸âƒ£ NOTE QUAN TRá»ŒNG
8.1 KhÃ´ng nÃªn Ä‘Ã¡nh giÃ¡ theo threshold 0.5

Camouflage/SOD khÃ´ng pháº£i binary segmentation cÆ¡ báº£n â†’
F-measure/FÎ² â‰  Weighted F-measure.

8.2 Báº¡n nÃªn bÃ¡o cÃ¡o:

S-measure

F<sub>w</sub>

E-measure

MAE

=> ÄÃ¢y lÃ  cáº¥u hÃ¬nh chuáº©n cÃ´ng bá»‘ SCI/Top-tier.

9ï¸âƒ£ CODE STRUCTURE Äá»€ XUáº¤T
.
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ mhcd_dataset.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ unetpp_bem.py
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ s_measure_paper.py
â”‚   â”œâ”€â”€ e_measure_paper.py
â”‚   â””â”€â”€ fweighted_measure.py
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ infer_folder.py
â”œâ”€â”€ logger_utils.py
â””â”€â”€ README.md

1ï¸âƒ£0ï¸âƒ£ Tá»I Æ¯U PERFORMANCE

torch.compile(model) tÄƒng ~15â€“40%

inference batch thay vÃ¬ áº£nh Ä‘Æ¡n

mixed precision:

with torch.amp.autocast("cuda"):


NÃªn táº¯t F<sub>w</sub> trong train epoch (ráº¥t cháº­m), chá»‰ test/val.

1ï¸âƒ£1ï¸âƒ£ CITATION SUGGESTION

Khi viáº¿t paper:

We adopt evaluation metrics widely used in camouflage object detection, including Structure-measure (S), Weighted F-measure (F<sub>w</sub>), Enhanced-measure (E), and Mean Absolute Error (MAE), following Fan et al. ICCVâ€™17, Fan et al. IJCAIâ€™18, and Margolin et al. CVPRâ€™14.